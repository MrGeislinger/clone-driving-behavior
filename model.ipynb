{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-the-Data\" data-toc-modified-id=\"Load-the-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Download-data-(if-needed)\" data-toc-modified-id=\"Download-data-(if-needed)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Download data (if needed)</a></span></li><li><span><a href=\"#Read-in-log-file\" data-toc-modified-id=\"Read-in-log-file-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Read in log file</a></span></li><li><span><a href=\"#Read-in-images-by-path-from-log-file\" data-toc-modified-id=\"Read-in-images-by-path-from-log-file-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Read in images by path from log file</a></span></li><li><span><a href=\"#Split-the-data-into-training-and-validation\" data-toc-modified-id=\"Split-the-data-into-training-and-validation-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Split the data into training and validation</a></span></li></ul></li><li><span><a href=\"#Data-Augmentation\" data-toc-modified-id=\"Data-Augmentation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Augmentation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Attempt-w/-ImageDataGenerator\" data-toc-modified-id=\"Attempt-w/-ImageDataGenerator-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Attempt w/ <code>ImageDataGenerator</code></a></span></li><li><span><a href=\"#Define-own-generator\" data-toc-modified-id=\"Define-own-generator-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Define own generator</a></span></li></ul></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-center-images-only\" data-toc-modified-id=\"Using-center-images-only-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Using center images only</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Evaluation</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:12.496466Z",
     "start_time": "2020-09-26T05:43:09.928352Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the log data & also load the images (found in the log file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:12.503131Z",
     "start_time": "2020-09-26T05:43:12.497979Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download data & unzip if it doesn't already exist\n",
    "import os.path\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:12.516186Z",
     "start_time": "2020-09-26T05:43:12.506673Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_ext_file(data_zip_url, data_path='data/'):\n",
    "    '''Download the zip file from URL and extract it to path (if specified).\n",
    "    '''\n",
    "    # Check if path already exits\n",
    "    if not os.path.exists(data_path):\n",
    "        with urlopen(data_zip_url) as zip_resp:\n",
    "            with ZipFile(BytesIO(zip_resp.read())) as zfile:\n",
    "                # Extract files into the data directory\n",
    "                zfile.extractall(path=None)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:12.525385Z",
     "start_time": "2020-09-26T05:43:12.519531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zip file contains the \"data\" and \"__MACOSX\" directories\n",
    "load_ext_file(\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip',\n",
    "    data_path='data/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:12.581530Z",
     "start_time": "2020-09-26T05:43:12.531202Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_img_meas_dfs(log_csv, data_dir=None, orig_dir=None, skiprows=None):\n",
    "    '''Creates DataFrames for the image paths and measurements using CSV path.\n",
    "    \n",
    "    Returns tuple of two DataFrames.\n",
    "    '''\n",
    "    data_header = [\n",
    "        'image_center',\n",
    "        'image_left',\n",
    "        'image_right',\n",
    "        'steer_angle', # [-1,1]\n",
    "        'throttle', # boolen (if accelerating)\n",
    "        'break', # boolean (if breaking)\n",
    "        'speed' # mph\n",
    "    ]\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        log_csv,\n",
    "        names=data_header,\n",
    "        skiprows=skiprows\n",
    "    )\n",
    "\n",
    "    # Replace the original directory from dataset (if specified)\n",
    "    if orig_dir and data_dir:\n",
    "        for col in ['image_center','image_left','image_right']:\n",
    "            df[col] = df[col].str.replace(orig_dir,data_dir)\n",
    "    \n",
    "    # Get specifics for each DF\n",
    "    df_img_paths = df.iloc[:,:3]\n",
    "    df_measurments = df.iloc[:,3:]\n",
    "    \n",
    "    return df_img_paths,df_measurments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:12.667072Z",
     "start_time": "2020-09-26T05:43:12.583277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_center</th>\n",
       "      <th>image_left</th>\n",
       "      <th>image_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_404.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_12_937.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_037.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_177.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image_center  \\\n",
       "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
       "1  IMG/center_2016_12_01_13_30_48_404.jpg   \n",
       "2  IMG/center_2016_12_01_13_31_12_937.jpg   \n",
       "3  IMG/center_2016_12_01_13_31_13_037.jpg   \n",
       "4  IMG/center_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                              image_left  \\\n",
       "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
       "1   IMG/left_2016_12_01_13_30_48_404.jpg   \n",
       "2   IMG/left_2016_12_01_13_31_12_937.jpg   \n",
       "3   IMG/left_2016_12_01_13_31_13_037.jpg   \n",
       "4   IMG/left_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                              image_right  \n",
       "0   IMG/right_2016_12_01_13_30_48_287.jpg  \n",
       "1   IMG/right_2016_12_01_13_30_48_404.jpg  \n",
       "2   IMG/right_2016_12_01_13_31_12_937.jpg  \n",
       "3   IMG/right_2016_12_01_13_31_13_037.jpg  \n",
       "4   IMG/right_2016_12_01_13_31_13_177.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for measurements:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steer_angle</th>\n",
       "      <th>throttle</th>\n",
       "      <th>break</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8036.000000</td>\n",
       "      <td>8036.000000</td>\n",
       "      <td>8036.000000</td>\n",
       "      <td>8036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.869660</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>28.169839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.128840</td>\n",
       "      <td>0.301326</td>\n",
       "      <td>0.036565</td>\n",
       "      <td>6.149327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.942695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.183093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.186400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.186640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.709360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       steer_angle     throttle        break        speed\n",
       "count  8036.000000  8036.000000  8036.000000  8036.000000\n",
       "mean      0.004070     0.869660     0.001970    28.169839\n",
       "std       0.128840     0.301326     0.036565     6.149327\n",
       "min      -0.942695     0.000000     0.000000     0.502490\n",
       "25%       0.000000     0.985533     0.000000    30.183093\n",
       "50%       0.000000     0.985533     0.000000    30.186400\n",
       "75%       0.000000     0.985533     0.000000    30.186640\n",
       "max       1.000000     0.985533     1.000000    30.709360"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs, df_meas = create_img_meas_dfs(log_csv='data/driving_log.csv',skiprows=1)\n",
    "\n",
    "display(df_imgs.head())\n",
    "\n",
    "print('Stats for measurements:')\n",
    "display(df_meas.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in images by path from log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:39.144313Z",
     "start_time": "2020-09-26T05:43:12.668586Z"
    }
   },
   "outputs": [],
   "source": [
    "center_images = []\n",
    "left_images = []\n",
    "right_images = []\n",
    "\n",
    "# TODO: Fix since this is a slow and inefficient process\n",
    "# Iterate over the different images\n",
    "data_dir = 'data/'\n",
    "for index,row in df_imgs.iterrows():\n",
    "    center_images.append(cv2.imread(data_dir+row['image_center'].strip()))\n",
    "    left_images.append(cv2.imread(data_dir+row['image_left'].strip()))\n",
    "    right_images.append(cv2.imread(data_dir+row['image_right'].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if image reading works\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure(figsize=(25,25))\n",
    "ax_left = f.add_subplot(1, 3, 1)\n",
    "ax_center = f.add_subplot(1, 3, 2)\n",
    "ax_right = f.add_subplot(1, 3, 3)\n",
    "\n",
    "# Print out an image example for each image type\n",
    "ax_center.imshow(images.get('center')[0])\n",
    "ax_left.imshow(images.get('left')[0])\n",
    "ax_right.imshow(images.get('right')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are splitting the data, we want to keep all the images (left, right,center) from the same timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:39.491354Z",
     "start_time": "2020-09-26T05:43:39.146072Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:42.031812Z",
     "start_time": "2020-09-26T05:43:39.493104Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creates (5th rank) tensor so multiple images as one data point\n",
    "X = np.array((left_images, center_images, right_images))\n",
    "X = np.transpose(X, (1,0,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:42.046796Z",
     "start_time": "2020-09-26T05:43:42.043569Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df_meas['steer_angle'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:49.636859Z",
     "start_time": "2020-09-26T05:43:42.048818Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do some data augmentation to the images to have more variety in the training material. We'll just do a horizontal flip here and only use the center images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt w/ `ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:49.649360Z",
     "start_time": "2020-09-26T05:43:49.641077Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.126359Z",
     "start_time": "2020-09-26T05:43:49.652449Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training and validation subsets have different number of classes after the split. If your numpy arrays are sorted by the label, you might want to shuffle them.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1bef7b670a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Only looking at center images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_generator = datagen.flow(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m valid_generator = datagen.flow(\n",
      "\u001b[0;32m~/anaconda3/envs/carnd_p01/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \"\"\"\n\u001b[0;32m--> 854\u001b[0;31m     return NumpyArrayIterator(\n\u001b[0m\u001b[1;32m    855\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd_p01/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m     super(NumpyArrayIterator, self).__init__(\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd_p01/lib/python3.8/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 np.array_equal(np.unique(y[:split_idx]),\n\u001b[1;32m    103\u001b[0m                                np.unique(y[split_idx:]))):\n\u001b[0;32m--> 104\u001b[0;31m                 raise ValueError('Training and validation subsets '\n\u001b[0m\u001b[1;32m    105\u001b[0m                                  \u001b[0;34m'have different number of classes after '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                                  \u001b[0;34m'the split. If your numpy arrays are '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Training and validation subsets have different number of classes after the split. If your numpy arrays are sorted by the label, you might want to shuffle them."
     ]
    }
   ],
   "source": [
    "# Only looking at center images \n",
    "# TODO: \n",
    "# Known issue for regression problems: https://github.com/keras-team/keras-preprocessing/issues/214\n",
    "# train_generator = datagen.flow(\n",
    "#     X_train[:,1,:], y=y_train, batch_size=64, shuffle=True, seed=27, subset='training'\n",
    "# )\n",
    "# valid_generator = datagen.flow(\n",
    "#     X_valid[:,1,:], y=y_valid, batch_size=64, shuffle=True, seed=27, subset='validation'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using center images only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try just using center images for training the model. If we simply put in the left and right images for the camera angle, we'd likely have issues with the model learning incorrect behavior. There are some techniques that could allow us to use these other images but for simplicity's sake we'll only use the center images for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.136541Z",
     "start_time": "2020-09-26T05:43:09.957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a resuable default convolution\n",
    "from functools import partial\n",
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_initializer='he_normal',\n",
    "                        kernel_size=3, activation='relu', padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.137929Z",
     "start_time": "2020-09-26T05:43:09.959Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.138812Z",
     "start_time": "2020-09-26T05:43:09.960Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on https://developer.nvidia.com/blog/deep-learning-self-driving-cars/\n",
    "model_list = [\n",
    "    # Normalize the images\n",
    "    keras.layers.Lambda(lambda x: (x/255.0) - 0.5, input_shape=input_shape),\n",
    "    DefaultConv2D(filters=24, kernel_size=5),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=36, kernel_size=5),\n",
    "    keras.layers.MaxPooling2D(pool_size=2), \n",
    "    DefaultConv2D(filters=48),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    # Fully connected network\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=1024, activation='relu'),\n",
    "#     keras.layers.Dropout(0.2),  # Dropout to regularize\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "#     keras.layers.Dropout(0.2),  # Dropout to regularize\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "#     keras.layers.Dropout(0.2),  # Dropout to regularize\n",
    "    keras.layers.Dense(units=16, activation='relu'),\n",
    "    keras.layers.Dense(units=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.139687Z",
     "start_time": "2020-09-26T05:43:09.962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding in model to crop images first\n",
    "model_list = (\n",
    "    [model_list[0]] +\n",
    "    # Crop out \"unnessary images\"\n",
    "    [keras.layers.Cropping2D(cropping=((60,20), (0,0)))] +\n",
    "    model_list[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.140743Z",
     "start_time": "2020-09-26T05:43:09.963Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.141798Z",
     "start_time": "2020-09-26T05:43:09.964Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='mse', \n",
    "    optimizer='nadam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.142457Z",
     "start_time": "2020-09-26T05:43:09.965Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.143450Z",
     "start_time": "2020-09-26T05:43:09.966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Allow early stopping after not changing significantly\n",
    "stop_after_5_no_change = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X=train_generator,\n",
    "    y=None, # Since using a generator\n",
    "    batch_size=None, # Since using a generator\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=30,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=800,\n",
    "    callbacks=[stop_after_5_no_change]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.144165Z",
     "start_time": "2020-09-26T05:43:09.968Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "def eval_model(model, model_history, X, y, show=True):\n",
    "    '''\n",
    "    '''\n",
    "    score = model.evaluate(X, y)\n",
    "    print(f'Loss: {score:.2f}')\n",
    "\n",
    "    if show:\n",
    "        plt.plot(model_history.history['loss'], label='Loss (training data)')\n",
    "        plt.plot(model_history.history['val_loss'], label='Loss (validation data)')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout how the previous model turned while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.145115Z",
     "start_time": "2020-09-26T05:43:09.969Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_model(model, history, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T05:43:50.145913Z",
     "start_time": "2020-09-26T05:43:09.970Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
